# Story 3.7: Content vs Function Word Ratio

**Status:** ✅ APPROVED
**Parent Epic:** Content-Aware Analysis System (Epic 3.0) - New Dimensions
**Estimated Effort:** 1 day
**Dependencies:** Story 1.4.11 (Dimension Registry)
**Priority:** MEDIUM (Research-proven: AI uses 15% more content words)
**Target Version:** 1.5.0

---

## Story

As a **technical writer analyzing document quality**,
I want **the analyzer to detect content/function word ratio imbalance**,
so that **I can identify AI's tendency to use 15% more content words** (nouns, verbs, adjectives) vs function words (the, and, is).

---

## Acceptance Criteria

### AC1: Word Classification
- [ ] Content words: Nouns, verbs, adjectives, adverbs (carry meaning)
- [ ] Function words: Determiners, prepositions, conjunctions, pronouns (grammatical structure)
- [ ] Uses POS tagging (spaCy) to classify words
- [ ] Calculates content/function ratio: `content_count / function_count`

### AC2: Ratio Scoring
- [ ] Human baseline: content/function ratio = 0.80-1.00 (balanced)
- [ ] AI typical: content/function ratio = 1.15-1.30 (15% more content words)
- [ ] EXCELLENT: ratio 0.80-1.00 (human-like balance)
- [ ] GOOD: ratio 1.00-1.10 (slight content bias)
- [ ] NEEDS WORK: ratio 1.10-1.20 (noticeable imbalance)
- [ ] POOR: ratio >1.20 (AI-like content word inflation)

### AC3: Content-Aware Assessment
- [ ] **Academic**: Higher ratio acceptable (1.05-1.20 = GOOD, dense terminology)
- [ ] **Blog**: Lower ratio expected (0.75-0.95 = EXCELLENT, conversational)
- [ ] **Technical Docs**: Moderate ratio (0.90-1.10 = GOOD, precise terminology)
- [ ] **Creative**: Lower ratio (0.70-0.90 = EXCELLENT, flowing prose)

### AC4: Self-Registration
- [ ] Dimension auto-registers via `@register_dimension` decorator
- [ ] Included in `balanced` and `full` dimension profiles
- [ ] Not in `fast` profile (requires POS tagging)

### AC5: Report Output
- [ ] Shows content/function ratio and counts
- [ ] Shows percentage deviation from baseline
- [ ] Lists top content words contributing to inflation
- [ ] Provides actionable guidance for balancing

### AC6: Performance & Testing
- [ ] Completes analysis in <0.05s for 10,000 word documents (POS tagging already cached)
- [ ] Memory <100KB additional (leverages existing spaCy pipeline)
- [ ] Unit tests achieve ≥85% coverage
- [ ] Validates against research benchmarks (15% inflation)

---

## Tasks/Subtasks

### Task 1: POS-Based Word Classification (0.25 days)
- [ ] Use existing spaCy POS tagging (already in syntactic dimension)
- [ ] Define content word POS tags: NOUN, VERB, ADJ, ADV
- [ ] Define function word POS tags: DET, ADP, CONJ, PRON, AUX
- [ ] Implement `classify_words(doc) -> Dict[str, List[str]]`

### Task 2: Ratio Calculation (0.25 days)
- [ ] Implement `calculate_content_function_ratio(content_count, function_count) -> float`
- [ ] Calculate deviation from human baseline (0.90)
- [ ] Identify top content words (for inflation analysis)

### Task 3: Dimension Implementation (0.25 days)
- [ ] Create `writescore/dimensions/content_function_ratio.py`
- [ ] Implement `ContentFunctionRatioDimension(BaseDimensionStrategy)`
- [ ] Integrate with dimension registry
- [ ] Add to balanced/full profiles

### Task 4: Content-Aware Assessment (0.1 days)
- [ ] Define ratio thresholds by content type
- [ ] Academic: 1.05-1.20 = GOOD
- [ ] Blog: 0.75-0.95 = EXCELLENT
- [ ] Integrate with content type scoring

### Task 5: Testing (0.15 days)
- [ ] Unit tests for word classification
- [ ] Unit tests for ratio calculation
- [ ] Content-aware assessment tests
- [ ] Validate 15% inflation threshold
- [ ] Performance benchmarks

### Task 6: Documentation (0.1 days)
- [ ] Update CHANGELOG.md
- [ ] Add dimension to README
- [ ] Document research foundation (15% content word increase)
- [ ] Provide usage examples

---

## Dev Notes

### Background Context

**Research Foundation** (Gehrmann et al., 2019):
- AI uses 15% more content words (nouns, verbs, adjectives) than humans
- Human baseline: content/function ratio ≈ 0.90 (10% fewer content words)
- AI typical: content/function ratio ≈ 1.15 (15% more content words)
- Reason: AI favors information density over natural flow

**Examples**:
- Human: "**The** system **is** **easy** **to** **use**" (2 content, 3 function, ratio: 0.67)
- AI: "**This** **innovative** **platform** **facilitates** **seamless** **utilization**" (6 content, 0 function, ratio: ∞)

**Content Type Baselines**:

| Content Type | Human Baseline | Acceptable Range | Assessment |
|--------------|----------------|------------------|------------|
| Academic | 1.05 | 1.00-1.20 | EXCELLENT |
| Professional Bio | 0.90 | 0.80-1.00 | EXCELLENT |
| Personal Statement | 0.85 | 0.75-0.95 | EXCELLENT |
| Blog | 0.80 | 0.70-0.90 | EXCELLENT |
| Technical Book | 0.95 | 0.85-1.05 | GOOD |
| Business | 0.90 | 0.80-1.00 | GOOD |
| Technical Docs | 1.00 | 0.90-1.10 | GOOD |
| Creative | 0.75 | 0.65-0.85 | EXCELLENT |
| News | 0.90 | 0.80-1.00 | GOOD |

### Implementation Strategy

**1. POS-Based Classification**
```python
# writescore/dimensions/content_function_ratio.py

from spacy.tokens import Doc

CONTENT_POS = {'NOUN', 'VERB', 'ADJ', 'ADV'}
FUNCTION_POS = {'DET', 'ADP', 'CONJ', 'SCONJ', 'PRON', 'AUX', 'PART'}

@register_dimension
class ContentFunctionRatioDimension(BaseDimensionStrategy):
    """Detects AI's 15% content word inflation"""

    dimension_name = "content_function_ratio"

    # Content-specific baselines
    HUMAN_BASELINES = {
        'academic': 1.05,
        'technical_book': 0.95,
        'technical_docs': 1.00,
        'business': 0.90,
        'professional_bio': 0.90,
        'personal_statement': 0.85,
        'blog': 0.80,
        'creative': 0.75,
        'news': 0.90,
        'generic': 0.90,
    }

    def analyze(self, text: str, content_type: Optional[str] = None) -> Dict[str, Any]:
        """Calculate content/function word ratio"""
        # Use existing spaCy doc from syntactic dimension if available
        doc = self._get_or_create_spacy_doc(text)

        # Classify words by POS
        content_words = []
        function_words = []

        for token in doc:
            if token.pos_ in CONTENT_POS:
                content_words.append(token.text)
            elif token.pos_ in FUNCTION_POS:
                function_words.append(token.text)

        content_count = len(content_words)
        function_count = len(function_words)

        # Calculate ratio
        ratio = content_count / function_count if function_count > 0 else float('inf')

        # Calculate deviation from baseline
        baseline = self.HUMAN_BASELINES.get(content_type or 'generic', 0.90)
        deviation_pct = ((ratio - baseline) / baseline) * 100

        # Assessment
        assessment = self._assess_ratio(ratio, deviation_pct, content_type)

        # Top content words (for inflation analysis)
        content_word_freq = {}
        for word in content_words:
            content_word_freq[word.lower()] = content_word_freq.get(word.lower(), 0) + 1

        top_content_words = sorted(content_word_freq.items(), key=lambda x: x[1], reverse=True)[:10]

        return {
            'content_count': content_count,
            'function_count': function_count,
            'ratio': ratio,
            'baseline': baseline,
            'deviation_pct': deviation_pct,
            'top_content_words': top_content_words,
            'assessment': assessment,
        }

    def _assess_ratio(self, ratio: float, deviation_pct: float, content_type: Optional[str]) -> str:
        """Assess content/function ratio"""

        # Generic assessment (15% inflation threshold)
        if content_type is None:
            if 0.80 <= ratio <= 1.00:
                return 'EXCELLENT'  # Human baseline
            elif 1.00 < ratio <= 1.10:
                return 'GOOD'  # Slight bias
            elif 1.10 < ratio <= 1.20:
                return 'NEEDS WORK'  # Noticeable imbalance
            else:
                return 'POOR'  # AI-like inflation (>20%)

        # Content-aware assessment
        baseline = self.HUMAN_BASELINES.get(content_type, 0.90)

        if abs(deviation_pct) <= 10:
            return 'EXCELLENT'  # Within 10% of baseline
        elif abs(deviation_pct) <= 20:
            return 'GOOD'  # Within 20%
        elif abs(deviation_pct) <= 30:
            return 'NEEDS WORK'
        else:
            return 'POOR'  # >30% deviation

    def format_results(self, results: Dict[str, Any]) -> str:
        """Format dimension results for report"""
        output = []

        ratio = results['ratio']
        baseline = results['baseline']
        deviation = results['deviation_pct']

        output.append(f"Content/Function Ratio: {ratio:.2f} (baseline: {baseline:.2f})")
        output.append(f"Content Words: {results['content_count']}, Function Words: {results['function_count']}")
        output.append(f"Deviation: {deviation:+.1f}%")

        if deviation > 15:
            output.append(f"\n⚠ High content word inflation detected (AI threshold: +15%)")
            output.append("→ ACTION: Add more function words for natural flow")
            output.append("  (Increase: the, a, is, to, for, and, etc.)")

        if results['top_content_words']:
            output.append(f"\nTop Content Words:")
            for word, count in results['top_content_words'][:5]:
                output.append(f"  • {word} ({count})")

        return "\n".join(output)
```

**2. Example Output**
```
Content/Function Ratio: POOR (Ratio: 1.28)

Content/Function Ratio: 1.28 (baseline: 0.90)
Content Words: 156, Function Words: 122
Deviation: +42.2%

⚠ High content word inflation detected (AI threshold: +15%)
→ ACTION: Add more function words for natural flow
  (Increase: the, a, is, to, for, and, etc.)

Top Content Words:
  • utilize (8)
  • facilitate (6)
  • implement (5)
  • optimize (4)
  • leverage (3)
```

### Performance Requirements

- **Analysis Time**: <0.05s (leverages existing spaCy doc)
- **Memory**: <100KB (minimal additional overhead)
- **POS Tagging**: Already performed by syntactic dimension

### Testing Requirements

**Unit Tests** (≥85% coverage):
```python
def test_balanced_content_function_ratio():
    """Human-like text has balanced ratio (0.80-1.00)"""
    text = "The system is easy to use and works well for most cases."

    dimension = ContentFunctionRatioDimension()
    results = dimension.analyze(text)

    assert 0.70 <= results['ratio'] <= 1.00
    assert results['assessment'] in ['EXCELLENT', 'GOOD']

def test_inflated_content_words():
    """AI-like text has inflated content words (ratio >1.15)"""
    text = "Innovative platform facilitates seamless utilization leveraging advanced methodologies optimizing outcomes."

    dimension = ContentFunctionRatioDimension()
    results = dimension.analyze(text)

    assert results['ratio'] > 1.15
    assert results['deviation_pct'] > 15
    assert results['assessment'] in ['NEEDS WORK', 'POOR']

def test_content_aware_academic_higher_ratio():
    """Academic writing tolerates higher ratio"""
    text = "Methodology facilitates comprehensive analysis utilizing statistical frameworks."

    dimension = ContentFunctionRatioDimension()
    results = dimension.analyze(text, content_type='academic')

    # Higher ratio acceptable for academic
    assert results['assessment'] in ['EXCELLENT', 'GOOD']
```

### Documentation Requirements

**CHANGELOG.md**:
```markdown
## [1.5.0] - 2025-XX-XX

### Added
- **Content/Function Word Ratio Dimension** (Story 3.7): Detects AI's 15% content word inflation
  - Research-proven AI marker (Gehrmann et al., 2019)
  - Measures content words (nouns, verbs, adjectives) vs function words (the, and, is)
  - Human baseline: ratio 0.90, AI typical: ratio 1.15
  - Content-aware baselines (academic=1.05, blog=0.80)
  - Reports top content words contributing to inflation
```

---

## QA Results

### Test Coverage
- [ ] Unit tests: ___% (Target: ≥85%)
- [ ] POS classification accuracy: 100%
- [ ] Ratio calculation validation: 15% threshold

---

## Change Log

| Date | Author | Change | Status |
|------|--------|--------|--------|
| 2025-01-XX | jmagady | Initial story creation | APPROVED |
