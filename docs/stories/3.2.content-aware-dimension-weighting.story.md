# Story 3.2: Content-Aware Dimension Weighting

**Status:** ✅ APPROVED
**Parent Epic:** Content-Aware Analysis System (Epic 3.0)
**Estimated Effort:** 3-4 days
**Dependencies:** Story 3.1 (Content Type Detection)
**Priority:** HIGH (Core functionality for content-aware scoring)
**Target Version:** 1.5.0

---

## Story

As a **technical writer analyzing different content types**,
I want **dimension weights to adjust based on content type (technical_book vs academic vs blog)**,
so that **dimensions critical for each genre receive appropriate emphasis in scoring**.

---

## Acceptance Criteria

### AC1: CONTENT_TYPE_WEIGHTS Configuration
- [ ] Define `CONTENT_TYPE_WEIGHTS` dict in new `content_type_config.py` module
- [ ] Includes weight profiles for all 9 content types
- [ ] Weights sum to 1.0 for each content type (validated)
- [ ] Dimensions marked CRITICAL receive 0.12-0.15 weight
- [ ] Dimensions marked HIGH receive 0.08-0.12 weight
- [ ] Dimensions marked MEDIUM receive 0.05-0.08 weight
- [ ] Dimensions marked LOW receive 0.02-0.05 weight
- [ ] Dimensions marked N/A receive 0.0 weight

### AC2: Weight Profile Examples (from CONTENT-TYPE-DIMENSION-MAPPING.md)
- [ ] **Technical Book** profile emphasizes:
  - `readability`: 0.15 (CRITICAL - must be accessible)
  - `burstiness`: 0.12 (HIGH - varied for engagement)
  - `advanced_lexical`: 0.12 (HIGH - rich explanations)
  - `perplexity`: 0.10 (HIGH - avoid AI buzzwords)
  - `structure`: 0.10 (MEDIUM - avoid formulaic chapters)
- [ ] **Academic** profile emphasizes:
  - `syntactic`: 0.15 (CRITICAL - complex sentences expected)
  - `readability`: 0.12 (HIGH - formal complexity acceptable)
  - `advanced_lexical`: 0.12 (HIGH - specialized vocabulary)
  - `voice`: 0.02 (LOW - 3rd person only)
  - `sentiment`: 0.02 (LOW - neutral expected)
- [ ] **Blog** profile emphasizes:
  - `voice`: 0.15 (CRITICAL - conversational required)
  - `sentiment`: 0.12 (HIGH - emotional variation)
  - `burstiness`: 0.12 (HIGH - punchy + varied)
  - `readability`: 0.10 (HIGH - accessibility)
  - `structure`: 0.05 (LOW - informal structure OK)

### AC3: WeightMediator Integration
- [ ] Extend `WeightMediator` to accept `content_type: Optional[str]` parameter
- [ ] `apply_content_weights(content_type: str) -> Dict[str, float]` method
- [ ] Validates that content-specific weights sum to 1.0 ± 0.01
- [ ] Falls back to balanced weights if content_type unknown or None
- [ ] Logs weight application: `Applied content weights for: technical_book`

### AC4: Analyzer Pipeline Integration
- [ ] Analyzer accepts content_type from AnalysisConfig
- [ ] Applies content-specific weights before dimension analysis
- [ ] AnalysisResults includes `applied_weights: Dict[str, float]` field
- [ ] Report shows active weight profile in header

### AC5: Quality Score Calculation
- [ ] DualScoreCalculator uses content-specific weights for quality score
- [ ] Weighted scoring formula: `quality_score = Σ(dimension_score × content_weight)`
- [ ] Detection risk uses inverse weighting (LOW-weighted dimensions contribute more to detection risk)
- [ ] Top Actions recommendations prioritize high-weighted dimensions

### AC6: Report Display
- [ ] Report header shows: `Content Type: Technical Book (weights: readability=0.15, burstiness=0.12, ...)`
- [ ] Dimension scores annotated with weights: `Readability (15.0%): POOR (Flesch: 12.5)`
- [ ] Quality score breakdown shows weighted contributions
- [ ] Top Actions sorted by: `dimension_weight × improvement_potential`

### AC7: Testing Coverage
- [ ] Unit tests achieve ≥85% coverage for content weighting module
- [ ] Test all 9 content type weight profiles sum to 1.0
- [ ] Test WeightMediator integration with content weights
- [ ] Test fallback to balanced weights when content_type=None
- [ ] Test quality score calculation with weighted dimensions

---

## Tasks/Subtasks

### Task 1: Content Type Weights Configuration (1 day)
- [ ] Create `writescore/core/content_type_config.py`
- [ ] Define `CONTENT_TYPE_WEIGHTS: Dict[str, Dict[str, float]]` with 9 profiles
- [ ] Implement `validate_content_weights(weights: Dict[str, float]) -> bool`
- [ ] Implement `get_content_weights(content_type: str) -> Dict[str, float]`
- [ ] Add validation: weights sum to 1.0 ± 0.01 for each content type

### Task 2: WeightMediator Extension (0.5 days)
- [ ] Add `content_type: Optional[str]` parameter to WeightMediator.__init__
- [ ] Implement `apply_content_weights(content_type: str) -> Dict[str, float]`
- [ ] Integrate content weights with existing weight validation
- [ ] Log weight application: `logger.info(f"Applied {content_type} weights")`
- [ ] Fallback to balanced weights if content_type unknown

### Task 3: AnalysisResults Extension (0.5 days)
- [ ] Add `applied_weights: Dict[str, float]` to AnalysisResults dataclass
- [ ] Add `content_type: Optional[str]` to AnalysisResults
- [ ] Store content-specific weights used during analysis
- [ ] Include in JSON export for reproducibility

### Task 4: Analyzer Integration (0.5 days)
- [ ] Modify Analyzer.analyze() to extract content_type from AnalysisConfig
- [ ] Pass content_type to WeightMediator
- [ ] Apply content weights before running dimensions
- [ ] Store applied weights in AnalysisResults

### Task 5: DualScoreCalculator Weighted Scoring (1 day)
- [ ] Modify `calculate_quality_score()` to use applied_weights from AnalysisResults
- [ ] Implement weighted scoring: `Σ(dimension_score × weight)`
- [ ] Update detection risk calculation with inverse weighting
- [ ] Update `get_top_actions()` to prioritize high-weighted dimensions
- [ ] Sort recommendations by: `weight × improvement_potential`

### Task 6: Report Formatting (0.5 days)
- [ ] Update report header to show content type and key weights
- [ ] Annotate dimension scores with weights: `Readability (15.0%): POOR`
- [ ] Add quality score breakdown showing weighted contributions
- [ ] Update Top Actions to show weight-aware prioritization

### Task 7: Testing (0.5 days)
- [ ] Unit tests for CONTENT_TYPE_WEIGHTS validation
- [ ] Unit tests for WeightMediator content weight application
- [ ] Integration tests with all 9 content types
- [ ] Test weighted quality score calculation
- [ ] Test fallback behavior (content_type=None)

### Task 8: Documentation (0.25 days)
- [ ] Update CHANGELOG.md with Story 3.2 changes
- [ ] Document content weight profiles in README
- [ ] Add usage examples showing weight-aware scoring
- [ ] Document weight validation rules

---

## Dev Notes

### Background Context

**Problem**: Current analyzer uses uniform dimension weighting regardless of content type. This causes inappropriate scoring:
- Professional bios penalized for low sentiment variance (genre-appropriate neutrality)
- Technical books penalized for moderate readability (Flesch 50-70 is *correct* for learning content)
- Academic writing rewarded for accessibility when formal complexity is expected

**Solution**: Content-aware dimension weighting adjusts the *importance* of each dimension based on genre conventions.

**Example - Technical Book Analysis**:
```
Current (uniform weighting):
  Readability: POOR (Flesch 55) → pulls quality score down
  Sentiment: POOR (variance 0.150) → pulls quality score down
  Quality Score: 62/100

Content-aware weighting (technical_book):
  Readability (15%): EXCELLENT (Flesch 55 = accessible for learning)
  Sentiment (8%): GOOD (variance 0.150 = appropriate enthusiasm)
  Quality Score: 87/100
```

**Weight Philosophy**:
- **CRITICAL (0.12-0.15)**: Genre-defining characteristics (e.g., readability for technical books)
- **HIGH (0.08-0.12)**: Important but not defining (e.g., burstiness for engagement)
- **MEDIUM (0.05-0.08)**: Supplementary signals (e.g., transition markers)
- **LOW (0.02-0.05)**: Minor considerations (e.g., syntactic for blogs)
- **N/A (0.0)**: Irrelevant or counter-productive for genre

### Implementation Strategy

**1. Content Type Weight Profiles**
```python
# writescore/core/content_type_config.py

CONTENT_TYPE_WEIGHTS = {
    'technical_book': {
        'readability': 0.15,          # CRITICAL - must be accessible (Flesch 50-70)
        'burstiness': 0.12,            # HIGH - varied for engagement over 300 pages
        'advanced_lexical': 0.12,      # HIGH - rich explanations with examples
        'perplexity': 0.10,            # HIGH - avoid AI buzzwords
        'figurative_language': 0.12,   # HIGH - metaphors aid learning
        'voice': 0.10,                 # HIGH - mixed 1st/2nd appropriate
        'structure': 0.10,             # MEDIUM - avoid formulaic chapters
        'sentiment': 0.08,             # MEDIUM - enthusiasm OK
        'transition_marker': 0.08,     # MEDIUM - conversational scaffolding
        'syntactic': 0.03,             # LOW - complex syntax not critical
        'formatting': 0.0,             # N/A - book formatting differs
        'lexical': 0.0,                # N/A - covered by advanced_lexical
        'predictability': 0.0,         # N/A - covered by perplexity
    },
    'academic': {
        'syntactic': 0.15,             # CRITICAL - complex sentences expected
        'readability': 0.12,           # HIGH - formal complexity acceptable (FRE 20-50)
        'advanced_lexical': 0.12,      # HIGH - specialized terminology
        'perplexity': 0.10,            # HIGH - domain-specific vocabulary
        'structure': 0.10,             # HIGH - formal organization
        'burstiness': 0.08,            # MEDIUM - some variation
        'transition_marker': 0.08,     # MEDIUM - logical connectors
        'figurative_language': 0.05,   # LOW - minimal metaphors
        'voice': 0.02,                 # LOW - 3rd person only
        'sentiment': 0.02,             # LOW - neutral expected
        'formatting': 0.0,             # N/A
        'lexical': 0.0,                # N/A
        'predictability': 0.0,         # N/A
    },
    'blog': {
        'voice': 0.15,                 # CRITICAL - conversational required
        'sentiment': 0.12,             # HIGH - emotional variation
        'burstiness': 0.12,            # HIGH - punchy + varied
        'readability': 0.10,           # HIGH - accessibility (Flesch 60-80)
        'perplexity': 0.10,            # HIGH - avoid AI buzzwords
        'advanced_lexical': 0.08,      # MEDIUM - some richness
        'figurative_language': 0.10,   # MEDIUM - engaging metaphors
        'transition_marker': 0.08,     # MEDIUM - conversational flow
        'structure': 0.05,             # LOW - informal OK
        'syntactic': 0.05,             # LOW - simple sentences OK
        'formatting': 0.05,            # LOW
        'lexical': 0.0,                # N/A
        'predictability': 0.0,         # N/A
    },
    'professional_bio': {
        'perplexity': 0.15,            # CRITICAL - avoid AI buzzwords
        'readability': 0.12,           # HIGH - clarity (Flesch 60-70)
        'advanced_lexical': 0.10,      # HIGH - professional vocabulary
        'burstiness': 0.10,            # HIGH - varied sentence structure
        'voice': 0.10,                 # HIGH - 3rd person consistency
        'structure': 0.08,             # MEDIUM - clear organization
        'syntactic': 0.08,             # MEDIUM - professional complexity
        'sentiment': 0.02,             # LOW - neutral expected (variance near 0)
        'transition_marker': 0.05,     # LOW
        'figurative_language': 0.05,   # LOW - minimal metaphors
        'formatting': 0.0,             # N/A
        'lexical': 0.0,                # N/A
        'predictability': 0.0,         # N/A
    },
    'personal_statement': {
        'voice': 0.15,                 # CRITICAL - 1st person required
        'sentiment': 0.15,             # CRITICAL - emotional variation
        'burstiness': 0.12,            # HIGH - narrative variation
        'advanced_lexical': 0.10,      # HIGH - rich storytelling
        'figurative_language': 0.12,   # HIGH - vivid descriptions
        'readability': 0.08,           # MEDIUM - accessible (Flesch 50-70)
        'perplexity': 0.08,            # MEDIUM - avoid AI clichés
        'structure': 0.08,             # MEDIUM - narrative flow
        'transition_marker': 0.07,     # MEDIUM
        'syntactic': 0.05,             # LOW
        'formatting': 0.0,             # N/A
        'lexical': 0.0,                # N/A
        'predictability': 0.0,         # N/A
    },
    'technical_docs': {
        'readability': 0.15,           # CRITICAL - scannable (Flesch 60-70)
        'structure': 0.15,             # CRITICAL - formulaic OK (findability)
        'perplexity': 0.12,            # HIGH - clear terminology
        'voice': 0.10,                 # HIGH - 2nd person imperative
        'burstiness': 0.08,            # MEDIUM - some variation
        'transition_marker': 0.08,     # MEDIUM - step-by-step connectors
        'syntactic': 0.08,             # MEDIUM - simple sentences preferred
        'advanced_lexical': 0.05,      # LOW - avoid complexity
        'sentiment': 0.02,             # LOW - neutral
        'figurative_language': 0.02,   # LOW - literal only
        'formatting': 0.0,             # N/A
        'lexical': 0.0,                # N/A
        'predictability': 0.0,         # N/A
    },
    'business': {
        'readability': 0.12,           # HIGH - clarity (Flesch 50-70)
        'perplexity': 0.12,            # HIGH - avoid jargon
        'structure': 0.10,             # HIGH - clear organization
        'burstiness': 0.10,            # HIGH - varied structure
        'voice': 0.10,                 # HIGH - mixed 1st/2nd
        'advanced_lexical': 0.08,      # MEDIUM - professional vocabulary
        'syntactic': 0.08,             # MEDIUM
        'transition_marker': 0.08,     # MEDIUM - logical flow
        'sentiment': 0.05,             # LOW - mostly neutral
        'figurative_language': 0.05,   # LOW
        'formatting': 0.0,             # N/A
        'lexical': 0.0,                # N/A
        'predictability': 0.0,         # N/A
    },
    'creative': {
        'burstiness': 0.15,            # CRITICAL - highly varied rhythm
        'sentiment': 0.15,             # CRITICAL - emotional depth
        'advanced_lexical': 0.12,      # HIGH - vivid vocabulary
        'figurative_language': 0.15,   # HIGH - metaphors/imagery
        'voice': 0.10,                 # HIGH - narrative voice
        'syntactic': 0.10,             # HIGH - varied complexity
        'perplexity': 0.08,            # MEDIUM - avoid AI patterns
        'readability': 0.05,           # LOW - complexity OK
        'transition_marker': 0.05,     # LOW
        'structure': 0.05,             # LOW - unconventional OK
        'formatting': 0.0,             # N/A
        'lexical': 0.0,                # N/A
        'predictability': 0.0,         # N/A
    },
    'news': {
        'readability': 0.15,           # CRITICAL - accessibility (Flesch 60-70)
        'perplexity': 0.12,            # HIGH - clear language
        'structure': 0.12,             # HIGH - inverted pyramid
        'voice': 0.10,                 # HIGH - 3rd person objective
        'burstiness': 0.08,            # MEDIUM - some variation
        'syntactic': 0.08,             # MEDIUM - clear syntax
        'transition_marker': 0.08,     # MEDIUM
        'advanced_lexical': 0.05,      # LOW - accessible vocabulary
        'sentiment': 0.02,             # LOW - objective tone
        'figurative_language': 0.02,   # LOW - literal reporting
        'formatting': 0.0,             # N/A
        'lexical': 0.0,                # N/A
        'predictability': 0.0,         # N/A
    },
}

def validate_content_weights(weights: Dict[str, float]) -> bool:
    """Validate that content type weights sum to 1.0 ± 0.01"""
    total = sum(weights.values())
    if not (0.99 <= total <= 1.01):
        raise WeightValidationError(
            f"Content weights sum to {total:.3f}, expected 1.0 ± 0.01",
            total_weight=total,
            expected_weight=1.0,
            tolerance=0.01
        )
    return True

def get_content_weights(content_type: str) -> Dict[str, float]:
    """Get dimension weights for specified content type"""
    if content_type not in CONTENT_TYPE_WEIGHTS:
        logger.warning(f"Unknown content type: {content_type}, using balanced weights")
        return None  # Triggers fallback to balanced weights

    weights = CONTENT_TYPE_WEIGHTS[content_type]
    validate_content_weights(weights)
    return weights
```

**2. WeightMediator Extension**
```python
# writescore/core/weight_mediator.py (MODIFY)

class WeightMediator:
    def __init__(
        self,
        dimension_registry: DimensionRegistry,
        content_type: Optional[str] = None
    ):
        self.registry = dimension_registry
        self.content_type = content_type
        self._weights: Optional[Dict[str, float]] = None

    def apply_content_weights(self, content_type: str) -> Dict[str, float]:
        """Apply content-specific dimension weights"""
        content_weights = get_content_weights(content_type)

        if content_weights is None:
            logger.info("Using balanced weights (no content type specified)")
            return self._get_balanced_weights()

        logger.info(f"Applied content weights for: {content_type}")
        self._weights = content_weights
        return content_weights

    def _get_balanced_weights(self) -> Dict[str, float]:
        """Fallback to uniform weighting across all dimensions"""
        dimension_count = len(self.registry.get_all_dimensions())
        return {dim: 1.0 / dimension_count for dim in self.registry.get_all_dimensions()}
```

**3. DualScoreCalculator Weighted Scoring**
```python
# writescore/scoring/dual_score_calculator.py (MODIFY)

def calculate_quality_score(
    self,
    results: AnalysisResults,
    weights: Optional[Dict[str, float]] = None
) -> float:
    """Calculate weighted quality score"""
    if weights is None:
        weights = results.applied_weights or self._get_default_weights()

    weighted_score = 0.0
    total_weight = 0.0

    for dimension, score in results.dimension_scores.items():
        weight = weights.get(dimension, 0.0)
        normalized_score = self._normalize_score(score)  # Convert to 0-100
        weighted_score += normalized_score * weight
        total_weight += weight

    return weighted_score / total_weight if total_weight > 0 else 0.0

def get_top_actions(
    self,
    results: AnalysisResults,
    weights: Optional[Dict[str, float]] = None,
    limit: int = 5
) -> List[Tuple[str, float]]:
    """Get top improvement actions prioritized by weight × potential"""
    if weights is None:
        weights = results.applied_weights or self._get_default_weights()

    actions = []
    for dimension, score in results.dimension_scores.items():
        weight = weights.get(dimension, 0.0)
        improvement_potential = 100 - self._normalize_score(score)
        priority = weight * improvement_potential
        actions.append((dimension, priority))

    return sorted(actions, key=lambda x: x[1], reverse=True)[:limit]
```

**4. Report Formatting**
```python
# writescore/formatters.py (MODIFY)

def format_dimension_scores(results: AnalysisResults) -> str:
    output = ["DIMENSION SCORES", "─" * 80]

    weights = results.applied_weights or {}

    for dimension, score in results.dimension_scores.items():
        weight = weights.get(dimension, 0.0)
        weight_pct = f"({weight*100:.1f}%)" if weight > 0 else ""

        output.append(
            f"{dimension.title()} {weight_pct:>8}: {score.assessment:>12}  "
            f"({score.details})"
        )

    return "\n".join(output)
```

### Relevant Source Tree

```
writescore/
├── core/
│   ├── content_type_config.py       # [NEW] CONTENT_TYPE_WEIGHTS configuration
│   ├── weight_mediator.py           # [MODIFY] Add content weight support
│   ├── analyzer.py                  # [MODIFY] Apply content weights
│   └── results.py                   # [MODIFY] Add applied_weights field
├── scoring/
│   └── dual_score_calculator.py     # [MODIFY] Weighted scoring
├── formatters.py                    # [MODIFY] Display weights in report
└── tests/
    └── unit/
        └── core/
            ├── test_content_type_config.py  # [NEW] Weight validation tests
            └── test_weighted_scoring.py     # [NEW] Weighted calculation tests
```

### Performance Requirements

- **Weight Application**: <0.001s overhead
- **Quality Score Calculation**: <0.01s with weighted scoring
- **Memory**: <100KB for weight configuration storage
- **Validation**: All weight profiles validated on module load

### Testing Requirements

**Unit Tests** (≥85% coverage):
```python
def test_content_weights_sum_to_one():
    """All content type weight profiles must sum to 1.0 ± 0.01"""
    for content_type, weights in CONTENT_TYPE_WEIGHTS.items():
        total = sum(weights.values())
        assert 0.99 <= total <= 1.01, f"{content_type} weights sum to {total}"

def test_technical_book_readability_critical():
    """Technical book profile gives readability highest weight"""
    weights = get_content_weights('technical_book')
    assert weights['readability'] == max(weights.values())
    assert weights['readability'] >= 0.15

def test_weighted_quality_score_calculation():
    """Quality score uses content-specific weights"""
    results = AnalysisResults(
        dimension_scores={
            'readability': 90,  # EXCELLENT
            'sentiment': 40,    # POOR
        },
        applied_weights={
            'readability': 0.15,  # High weight
            'sentiment': 0.08,    # Low weight
        }
    )

    calculator = DualScoreCalculator()
    score = calculator.calculate_quality_score(results)

    # Score should be pulled up by high-weighted readability
    assert score > 75

def test_fallback_to_balanced_weights():
    """Unknown content type falls back to balanced weights"""
    weights = get_content_weights('unknown_type')
    assert weights is None  # Triggers balanced fallback
```

**Integration Tests**:
```python
def test_technical_book_analysis_with_weights():
    """Technical book analysis applies correct weight profile"""
    text = "# Chapter 1\n\nLet me show you how neural networks work..."

    config = AnalysisConfig(
        content_type='technical_book',
        dimension_profile='full'
    )

    results = analyzer.analyze(text, config)

    assert results.content_type == 'technical_book'
    assert results.applied_weights['readability'] == 0.15
    assert results.applied_weights['sentiment'] == 0.08
```

### Documentation Requirements

**CHANGELOG.md**:
```markdown
## [1.5.0] - 2025-XX-XX

### Added
- **Content-Aware Dimension Weighting** (Story 3.2): Dimensions now weighted by content type importance
  - CONTENT_TYPE_WEIGHTS configuration with profiles for 9 content types
  - WeightMediator applies content-specific weights before analysis
  - Quality scores calculated using weighted dimension contributions
  - Top Actions recommendations prioritize high-weighted dimensions
  - Report displays active weight profile and dimension importance percentages
  - Example: Technical books emphasize readability (15%), burstiness (12%), advanced_lexical (12%)
  - Falls back to balanced weights if content type unknown
```

**README.md**:
```markdown
## Content-Aware Dimension Weighting

Different content types emphasize different dimensions:

```bash
# Technical book analysis (readability weighted 15%, sentiment 8%)
python analyze_ai_patterns.py chapter-01.md --content-type technical_book

# Output:
# Content Type: Technical Book (weights: readability=15%, burstiness=12%, advanced_lexical=12%)
#
# DIMENSION SCORES
# Readability (15.0%): EXCELLENT (Flesch: 62.5)
# Sentiment (8.0%):    GOOD     (Variance: 0.150)
#
# Quality Score: 87.2/100 (weighted)
```

**Weight Philosophy**:
- CRITICAL (12-15%): Genre-defining characteristics
- HIGH (8-12%): Important but not defining
- MEDIUM (5-8%): Supplementary signals
- LOW (2-5%): Minor considerations
- N/A (0%): Irrelevant for genre
```

---

## QA Results

### Test Coverage
- [ ] Unit tests: ___% (Target: ≥85%)
- [ ] Integration tests: ___ passing
- [ ] Weight validation tests: 9/9 content types pass

### Performance Benchmarks
- [ ] Weight application: ___ms (Target: <1ms)
- [ ] Weighted quality score: ___ms (Target: <10ms)
- [ ] Memory overhead: ___KB (Target: <100KB)

### Manual Validation
- [ ] Tested all 9 content type weight profiles
- [ ] Verified quality scores reflect weighted importance
- [ ] Confirmed Top Actions prioritize high-weighted dimensions
- [ ] Validated fallback to balanced weights

---

## Change Log

| Date | Author | Change | Status |
|------|--------|--------|--------|
| 2025-01-XX | jmagady | Initial story creation | APPROVED |
